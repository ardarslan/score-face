{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Score SDE demo PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.9 64-bit ('face_sde': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "fc821e6bf1651ef755e762dd1ddbc288afbd25b09681fdc022fdcbfc8b15bfff"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "# Choose a python which is not a conda environment from top right.\n",
        "!module load gcc/8.2.0 python_gpu/3.9.9 eth_proxy"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The following have been reloaded with a version change:\n",
            "  1) gcc/6.3.0 => gcc/8.2.0\n",
            "\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "#@title Autoload all modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import importlib\n",
        "import os\n",
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"../\")\n",
        "from losses import get_optimizer\n",
        "from models.ema import ExponentialMovingAverage\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_gan as tfgan\n",
        "import tqdm\n",
        "import io\n",
        "import likelihood\n",
        "import controllable_generation\n",
        "from utils import restore_checkpoint\n",
        "sns.set(font_scale=2)\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "import models\n",
        "from models import utils as mutils\n",
        "from models import ncsnv2\n",
        "from models import ncsnpp\n",
        "from models import ddpm as ddpm_model\n",
        "from models import layerspp\n",
        "from models import layers\n",
        "from models import normalization\n",
        "import sampling\n",
        "from likelihood import get_likelihood_fn\n",
        "from sde_lib import VESDE\n",
        "from sampling import (ReverseDiffusionPredictor, \n",
        "                      LangevinCorrector, \n",
        "                      EulerMaruyamaPredictor, \n",
        "                      AncestralSamplingPredictor, \n",
        "                      NoneCorrector, \n",
        "                      NonePredictor,\n",
        "                      AnnealedLangevinDynamics)\n",
        "import datasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "/cluster/home/aarslan/.cache/torch_extensions/py39_cu113/fused/fused.so: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m mutils\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ncsnv2\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ncsnpp\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ddpm \u001b[38;5;28;01mas\u001b[39;00m ddpm_model\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layerspp\n",
            "File \u001b[0;32m~/face_sde/nbs/../models/ncsnpp.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The Google Research Authors.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: skip-file\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils, layers, layerspp, normalization\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n",
            "File \u001b[0;32m~/face_sde/nbs/../models/layerspp.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Layers for defining NCSN++.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m up_or_down_sampling\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "File \u001b[0;32m~/face_sde/nbs/../models/up_or_down_sampling.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upfirdn2d\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Function ported from StyleGAN2\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weight\u001b[39m(module,\n\u001b[1;32m     15\u001b[0m                shape,\n\u001b[1;32m     16\u001b[0m                weight_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m                kernel_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
            "File \u001b[0;32m~/face_sde/nbs/../op/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfused_act\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FusedLeakyReLU, fused_leaky_relu\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupfirdn2d\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upfirdn2d\n",
            "File \u001b[0;32m~/face_sde/nbs/../op/fused_act.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcpp_extension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m     10\u001b[0m module_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m fused \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused_bias_act.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused_bias_act_kernel.cu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFusedLeakyReLUFunctionBackward\u001b[39;00m(Function):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, grad_output, out, negative_slope, scale):\n",
            "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/face_sde/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1144\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m   1054\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   1055\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1064\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m                verbose=True)\u001b[39;00m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m-> 1144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/face_sde/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1382\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[1;32m   1380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[0;32m-> 1382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/face_sde/lib/python3.9/site-packages/torch/utils/cpp_extension.py:1775\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_python_module:\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;66;03m# https://stackoverflow.com/questions/67631/how-to-import-a-module-given-the-full-path\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m     spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[0;32m-> 1775\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m   1777\u001b[0m     spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
            "\u001b[0;31mImportError\u001b[0m: /cluster/home/aarslan/.cache/torch_extensions/py39_cu113/fused/fused.so: cannot open shared object file: No such file or directory"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Load the score-based model\n",
        "sde = 'VESDE' #@param ['VESDE', 'VPSDE', 'subVPSDE'] {\"type\": \"string\"}\n",
        "if sde.lower() == 'vesde':\n",
        "  from configs.ve import cifar10_ncsnpp_continuous as configs\n",
        "  ckpt_filename = \"exp/ve/cifar10_ncsnpp_continuous/checkpoint_24.pth\"\n",
        "  config = configs.get_config()  \n",
        "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-5\n",
        "elif sde.lower() == 'vpsde':\n",
        "  from configs.vp import cifar10_ddpmpp_continuous as configs  \n",
        "  ckpt_filename = \"exp/vp/cifar10_ddpmpp_continuous/checkpoint_8.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = VPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "elif sde.lower() == 'subvpsde':\n",
        "  from configs.subvp import cifar10_ddpmpp_continuous as configs\n",
        "  ckpt_filename = \"exp/subvp/cifar10_ddpmpp_continuous/checkpoint_26.pth\"\n",
        "  config = configs.get_config()\n",
        "  sde = subVPSDE(beta_min=config.model.beta_min, beta_max=config.model.beta_max, N=config.model.num_scales)\n",
        "  sampling_eps = 1e-3\n",
        "\n",
        "batch_size =   64#@param {\"type\":\"integer\"}\n",
        "config.training.batch_size = batch_size\n",
        "config.eval.batch_size = batch_size\n",
        "\n",
        "random_seed = 0 #@param {\"type\": \"integer\"}\n",
        "\n",
        "sigmas = mutils.get_sigmas(config)\n",
        "scaler = datasets.get_data_scaler(config)\n",
        "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
        "score_model = mutils.create_model(config)\n",
        "\n",
        "optimizer = get_optimizer(config, score_model.parameters())\n",
        "ema = ExponentialMovingAverage(score_model.parameters(),\n",
        "                               decay=config.model.ema_rate)\n",
        "state = dict(step=0, optimizer=optimizer,\n",
        "             model=score_model, ema=ema)\n",
        "\n",
        "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
        "ema.copy_to(score_model.parameters())"
      ],
      "outputs": [],
      "metadata": {
        "id": "-reedYgCU79v",
        "cellView": "form"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Visualization code\n",
        "\n",
        "def image_grid(x):\n",
        "  size = config.data.image_size\n",
        "  channels = config.data.num_channels\n",
        "  img = x.reshape(-1, size, size, channels)\n",
        "  w = int(np.sqrt(img.shape[0]))\n",
        "  img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
        "  return img\n",
        "\n",
        "def show_samples(x):\n",
        "  x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
        "  img = image_grid(x)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "G8ei2Xsfg6JQ",
        "cellView": "form"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictor Corrector sampling\n",
        "\n",
        "\n",
        "Recommended settings:\n",
        "\n",
        " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
        "\n",
        "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
      ],
      "metadata": {
        "id": "8hbBGjCMNUsp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title PC sampling\n",
        "img_size = config.data.image_size\n",
        "channels = config.data.num_channels\n",
        "shape = (batch_size, channels, img_size, img_size)\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps =  1#@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
        "                                      inverse_scaler, snr, n_steps=n_steps,\n",
        "                                      probability_flow=probability_flow,\n",
        "                                      continuous=config.training.continuous,\n",
        "                                      eps=sampling_eps, device=config.device)\n",
        "\n",
        "x, n = sampling_fn(score_model)\n",
        "show_samples(x)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "_X41BhiLqJvM",
        "cellView": "form",
        "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probability flow ODE\n",
        "\n",
        "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
      ],
      "metadata": {
        "id": "0AdiQdwN2aFA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        " #@title ODE sampling\n",
        "\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
        "                                       shape, \n",
        "                                       inverse_scaler,                                       \n",
        "                                       denoise=True, \n",
        "                                       eps=sampling_eps,\n",
        "                                       device=config.device)\n",
        "x, nfe = sampling_fn(score_model)\n",
        "show_samples(x)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "iLQDfFvHSIGn",
        "cellView": "form",
        "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Likelihood computation\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
        "                                             inverse_scaler,                                             \n",
        "                                             eps=1e-5)\n",
        "for batch in eval_iter:\n",
        "  img = batch['image']._numpy()\n",
        "  img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
        "  img = scaler(img)\n",
        "  bpd, z, nfe = likelihood_fn(score_model, img)\n",
        "  bpds.extend(bpd)\n",
        "  print(f\"average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "MsdcLnhu7s46",
        "cellView": "form"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Representations\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
        "eval_batch = next(iter(eval_ds))\n",
        "eval_images = eval_batch['image']._numpy()\n",
        "shape = (batch_size, 3, 32, 32)\n",
        "\n",
        "likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
        "sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
        "                                       denoise=True, eps=sampling_eps, device=config.device)\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(eval_images))\n",
        "plt.title('Original images')\n",
        "\n",
        "eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
        "_, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
        "\n",
        "x, nfe = sampling_fn(score_model, latent_z)\n",
        "\n",
        "x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.axis('off')\n",
        "plt.imshow(image_grid(x))\n",
        "plt.title('Reconstructed images')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "oe3rLGRm28nc",
        "cellView": "form",
        "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Controllable generation\n",
        "\n",
        "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
        "\n",
        "Recommended settings\n",
        "\n",
        "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
        "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
        "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
        "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
        "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
        "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
        "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
      ],
      "metadata": {
        "id": "kaGYVD7KcoW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title PC inpainting\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
        "                                                        predictor, corrector,\n",
        "                                                        inverse_scaler,\n",
        "                                                        snr=snr,\n",
        "                                                        n_steps=n_steps,\n",
        "                                                        probability_flow=probability_flow,\n",
        "                                                        continuous=config.training.continuous,\n",
        "                                                        denoise=True)\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "\n",
        "mask = torch.ones_like(img)\n",
        "mask[:, :, :, 16:] = 0.\n",
        "show_samples(img * mask)\n",
        "\n",
        "\n",
        "x = pc_inpainter(score_model, scaler(img), mask)\n",
        "show_samples(x)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbly_8RIjqJD",
        "cellView": "form",
        "outputId": "28ca290e-1079-4031-e37a-c69374398f76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title PC colorizer\n",
        "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
        "eval_iter = iter(eval_ds)\n",
        "bpds = []\n",
        "\n",
        "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
        "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
        "snr = 0.16 #@param {\"type\": \"number\"}\n",
        "n_steps = 1 #@param {\"type\": \"integer\"}\n",
        "probability_flow = False #@param {\"type\": \"boolean\"}\n",
        "\n",
        "batch = next(eval_iter)\n",
        "img = batch['image']._numpy()\n",
        "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
        "show_samples(img)\n",
        "gray_scale_img = torch.mean(img, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
        "show_samples(gray_scale_img)\n",
        "gray_scale_img = scaler(gray_scale_img)\n",
        "pc_colorizer = controllable_generation.get_pc_colorizer(\n",
        "    sde, predictor, corrector, inverse_scaler,\n",
        "    snr=snr, n_steps=n_steps, probability_flow=probability_flow,\n",
        "    continuous=config.training.continuous, denoise=True\n",
        ")\n",
        "x = pc_colorizer(score_model, gray_scale_img)\n",
        "\n",
        "show_samples(x)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DsP-ayb8cupk",
        "cellView": "form",
        "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class-conditional generation\n",
        "\n"
      ],
      "metadata": {
        "id": "HiYRNB-Wk329"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
      ],
      "metadata": {
        "id": "HTu-5e6S68Gb"
      }
    }
  ]
}