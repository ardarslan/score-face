{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pytorch3d.io import load_obj\n",
    "from pytorch3d.renderer.mesh import Textures\n",
    "from pytorch3d.structures import Meshes\n",
    "from pytorch3d.renderer.mesh.shader import ShaderBase\n",
    "from pytorch3d.renderer.mesh.rasterizer import Fragments\n",
    "from pytorch3d.renderer.mesh.shading import phong_shading\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVPerspectiveCameras,\n",
    "    RasterizationSettings, \n",
    "    MeshRenderer, \n",
    "    MeshRasterizer\n",
    ")\n",
    "\n",
    "\n",
    "class HardPhongShader(ShaderBase):\n",
    "    \"\"\"\n",
    "    Per pixel lighting - the lighting model is applied using the interpolated\n",
    "    coordinates and normals for each pixel. The blending function hard assigns\n",
    "    the color of the closest face for each pixel.\n",
    "    To use the default values, simply initialize the shader with the desired\n",
    "    device e.g.\n",
    "    .. code-block::\n",
    "        shader = HardPhongShader(device=torch.device(\"cuda:0\"))\n",
    "    \"\"\"\n",
    "    def __init__(self, backgrounds, *args, **kwargs):\n",
    "        self.backgrounds = backgrounds\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def _hard_rgb_blend(self, colors: torch.Tensor, backgrounds: torch.Tensor, fragments: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Naive blending of top K faces to return an RGBA image\n",
    "        - **RGB** - choose color of the closest point i.e. K=0\n",
    "        - **A** - 1.0\n",
    "\n",
    "        Args:\n",
    "            colors: (N, H, W, K, 3) RGB color for each of the top K faces per pixel.\n",
    "            fragments: the outputs of rasterization. From this we use\n",
    "                - pix_to_face: LongTensor of shape (N, H, W, K) specifying the indices\n",
    "                of the faces (in the packed representation) which\n",
    "                overlap each pixel in the image. This is used to\n",
    "                determine the output shape.\n",
    "            blend_params: BlendParams instance that contains a background_color\n",
    "            field specifying the color for the background\n",
    "        Returns:\n",
    "            RGBA pixel_colors: (N, H, W, 4)\n",
    "        \"\"\"\n",
    "\n",
    "        # Mask for the background.\n",
    "        is_background = (fragments.pix_to_face[..., 0] < 0)\n",
    "        mask = is_background.unsqueeze(-1).repeat(1, 1, 1, 3)  # (N, H, W, 3)\n",
    "        pixel_colors = torch.where(mask, backgrounds, colors[..., 0, :])\n",
    "        # Concat with the alpha channel.\n",
    "        alpha = (~is_background).type_as(pixel_colors)[..., None]\n",
    "        return torch.cat([pixel_colors, alpha], dim=-1)  # (N, H, W, 4)\n",
    "\n",
    "    def forward(self, fragments: Fragments, meshes: Meshes, **kwargs) -> torch.Tensor:\n",
    "        cameras = kwargs.get(\"cameras\", self.cameras)\n",
    "        texels = meshes.sample_textures(fragments)\n",
    "        lights = kwargs.get(\"lights\", self.lights)\n",
    "        materials = kwargs.get(\"materials\", self.materials)\n",
    "        backgrounds = kwargs.get(\"backgrounds\", self.backgrounds)\n",
    "        colors = phong_shading(\n",
    "            meshes=meshes,\n",
    "            fragments=fragments,\n",
    "            texels=texels,\n",
    "            lights=lights,\n",
    "            cameras=cameras,\n",
    "            materials=materials,\n",
    "        )\n",
    "        images = self._hard_rgb_blend(colors, backgrounds, fragments)\n",
    "        return images\n",
    "\n",
    "\n",
    "class Renderer(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.raster_settings = RasterizationSettings(\n",
    "            image_size=cfg[\"image_size\"],\n",
    "            blur_radius=0.0,\n",
    "            bin_size=0,\n",
    "        )\n",
    "        obj_path = self.cfg[\"obj_path\"]\n",
    "        self.verts, self.faces, self.aux = load_obj(obj_path, device=self.cfg[\"device\"])\n",
    "        self.verts_uvs = self.aux.verts_uvs[None, ...]  # (1, V, 2)\n",
    "        self.faces_uvs = self.faces.textures_idx[None, ...]  # (1, F, 3)\n",
    "\n",
    "        if self.cfg['render_mode'] in [\"2d\", \"2d_modified\", \"background\"]:\n",
    "            self.render = self._render_2d\n",
    "        elif self.cfg['render_mode'] == \"3d\":\n",
    "            self.render = self._render_3d\n",
    "        else:\n",
    "            raise Exception(f\"Not a valid render_mode {self.cfg['render_mode']}.\")\n",
    "    \n",
    "    def get_random_elev_azimuth(self):\n",
    "        if self.cfg[\"elev_azimuth_random\"]:\n",
    "            elev = np.random.random() * 30 - 60\n",
    "            azimuth = np.random.random() * 30 - 60\n",
    "        else:\n",
    "            elev = 0.0\n",
    "            azimuth = 0.0\n",
    "        return elev, azimuth\n",
    "    \n",
    "    def _get_foreground_mask(self, elev, azimuth):\n",
    "        cfg = self.cfg\n",
    "        texture = torch.ones(size=(cfg[\"batch_size\"], cfg[\"num_channels\"], cfg[\"texture_size\"], cfg[\"texture_size\"]), device=cfg[\"device\"])\n",
    "        background = torch.zeros(size=(cfg[\"batch_size\"], cfg[\"num_channels\"], cfg[\"image_size\"], cfg[\"image_size\"]), device=cfg[\"device\"])\n",
    "        face = self._render_3d(texture=texture, background=background, elev=elev, azimuth=azimuth, return_face_mean=True, j=None, rsde=None, vec_t=None, z=None, noise_face=None, step_size_face=None)\n",
    "        foreground_mask = (face > 0)\n",
    "        return foreground_mask\n",
    "    \n",
    "    def _predict_helper(self, face, rsde, vec_t, z):\n",
    "        f, G = rsde.discretize(face.detach(), vec_t)\n",
    "        face = face - f\n",
    "        face = face + G[:, None, None, None] * z\n",
    "        return face\n",
    "\n",
    "    def _predict(self, face, j, rsde, vec_t, z):\n",
    "        if self.cfg[\"predict\"] == \"face_once\":\n",
    "            if j == self.cfg[\"num_corrector_steps\"] - 1:\n",
    "                face = self._predict_helper(face, rsde, vec_t, z)\n",
    "                return face\n",
    "            else:\n",
    "                return face\n",
    "        elif self.cfg[\"predict\"] == \"face_always\":\n",
    "            face = self._predict_helper(face, rsde, vec_t, z)\n",
    "            return face\n",
    "        elif self.cfg[\"predict\"] in [\"never\", \"texture_and_background\"]:\n",
    "            return face\n",
    "        else:\n",
    "            raise Exception(f\"Not a valid predict {self.cfg['predict']}.\")\n",
    "    \n",
    "    def _add_noise(self, face, noise_face, step_size_face):\n",
    "        if self.cfg[\"add_noise\"] == \"face\":\n",
    "            face = face + torch.sqrt(step_size_face * 2)[:, None, None, None] * noise_face * self.cfg[\"face_noise_coefficient\"]\n",
    "            return face\n",
    "        else:\n",
    "            return face\n",
    "    \n",
    "    def _render_2d(self, texture, background, elev, azimuth, return_face_mean, j, rsde, vec_t, z, noise_face, step_size_face):\n",
    "        \"\"\"\n",
    "            Inputs:\n",
    "                texture: torch.tensor with shape (N, C, H, W)\n",
    "                background: torch.tensor with shape (N, C, H, W)\n",
    "                elev: float\n",
    "                azimuth: float\n",
    "                return_face_mean: bool\n",
    "                j: int\n",
    "                rsde: RSDE\n",
    "                vec_t : torch.Tensor\n",
    "                z: torch.Tensor\n",
    "                noise_face: torch.Tensor\n",
    "                step_size_face: torch.Tensor\n",
    "            Outputs:\n",
    "                face: (N, C, H, W)\n",
    "        \"\"\"\n",
    "        foreground_mask = self._get_foreground_mask(elev, azimuth)\n",
    "        if self.cfg[\"render_mode\"] == \"background\":\n",
    "            face = background\n",
    "        elif self.cfg[\"render_mode\"] == \"2d_modified\":\n",
    "            face = torch.where(foreground_mask, texture * 100, background)\n",
    "        elif self.cfg[\"render_mode\"] == \"2d\":\n",
    "            face = torch.where(foreground_mask, texture, background)\n",
    "        else:\n",
    "            raise Exception(f\"Not a a valid render_mode {self.cfg['render_mode']}.\")\n",
    "        \n",
    "        if return_face_mean:\n",
    "            return face\n",
    "        else:\n",
    "            face = self._predict(face, j, rsde, vec_t, z)\n",
    "            face = self._add_noise(face, noise_face, step_size_face)\n",
    "            return face\n",
    "\n",
    "    def _render_3d(self, texture, background, elev, azimuth, return_face_mean, j, rsde, vec_t, z, noise_face, step_size_face):\n",
    "        \"\"\"\n",
    "            Inputs:\n",
    "                texture: torch.tensor with shape (N, C, H, W)\n",
    "                background: torch.tensor with shape (N, C, H, W)\n",
    "                elev: float\n",
    "                azimuth: float\n",
    "                return_face_mean: bool\n",
    "                j: int\n",
    "                rsde: RSDE\n",
    "                vec_t : torch.Tensor\n",
    "                z: torch.Tensor\n",
    "                noise_face: torch.Tensor\n",
    "                step_size_face: torch.Tensor\n",
    "            Outputs:\n",
    "                face: (N, C, H, W)\n",
    "        \"\"\"\n",
    "        tex = Textures(verts_uvs=self.verts_uvs, faces_uvs=self.faces_uvs, maps=texture.permute(0, 2, 3, 1))\n",
    "\n",
    "        meshes = Meshes(verts=[self.verts], faces=[self.faces.verts_idx], textures=tex)\n",
    "        verts_packed = meshes.verts_packed()\n",
    "        center = verts_packed.mean(0)\n",
    "        scale = max((verts_packed - center).abs().max(0)[0])\n",
    "        meshes.offset_verts_(-center)\n",
    "        meshes.scale_verts_((1.0 / float(scale)))\n",
    "        R, T = look_at_view_transform(1.0, elev, azimuth)\n",
    "        cameras = FoVPerspectiveCameras(R=R, T=T, device=self.cfg[\"device\"])\n",
    "        renderer = MeshRenderer(\n",
    "            rasterizer=MeshRasterizer(\n",
    "                cameras=cameras, \n",
    "                raster_settings=self.raster_settings\n",
    "            ),\n",
    "            shader=HardPhongShader(\n",
    "                device=self.cfg[\"device\"], \n",
    "                cameras=cameras,\n",
    "                backgrounds=background.permute(0, 2, 3, 1)\n",
    "            )\n",
    "        )\n",
    "        face = renderer(meshes)[:, :, :, :3].permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
    "        if return_face_mean:\n",
    "            return face\n",
    "        else:\n",
    "            face = self._predict(face, j, rsde, vec_t, z)\n",
    "            face = self._add_noise(face, noise_face, step_size_face)\n",
    "            return face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.\n",
      "Traceback (most recent call last):\n",
      "  File \"/local/home/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/iopath/common/file_io.py\", line 946, in __log_tmetry_keys\n",
      "    handler.log_event()\n",
      "  File \"/local/home/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/iopath/common/event_logger.py\", line 97, in log_event\n",
      "    del self._evt\n",
      "AttributeError: _evt\n",
      "/local/home/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/pytorch3d/io/utils.py:66: UserWarning: Faces have invalid indices\n",
      "  warnings.warn(\"Faces have invalid indices\")\n"
     ]
    }
   ],
   "source": [
    "obj_path = \"../assets/20705.obj\"\n",
    "\n",
    "verts, faces, aux = load_obj(obj_path, device=\"cuda\")\n",
    "verts_uvs = aux.verts_uvs[None, ...]  # (1, V, 2)\n",
    "faces_uvs = faces.textures_idx[None, ...]  # (1, F, 3)\n",
    "\n",
    "texture = torch.randn(size=(1, 3, 256, 256), device=\"cuda\")\n",
    "\n",
    "tex = Textures(verts_uvs=verts_uvs, faces_uvs=faces_uvs, maps=texture.permute(0, 2, 3, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytorch3d.renderer.mesh.textures.TexturesUV at 0x7faf482ce130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "packing_list = [\n",
    "    i[j] for i, j in zip(verts_uvs, self.faces_uvs_list())\n",
    "]\n",
    "faces_verts_uvs = torch.cat(packing_list)\n",
    "texture_maps = self.maps_padded()\n",
    "\n",
    "# pixel_uvs: (N, H, W, K, 2)\n",
    "pixel_uvs = interpolate_face_attributes(\n",
    "    fragments.pix_to_face, fragments.bary_coords, faces_verts_uvs\n",
    ")\n",
    "\n",
    "N, H_out, W_out, K = fragments.pix_to_face.shape\n",
    "N, H_in, W_in, C = texture_maps.shape  # 3 for RGB\n",
    "\n",
    "# pixel_uvs: (N, H, W, K, 2) -> (N, K, H, W, 2) -> (NK, H, W, 2)\n",
    "pixel_uvs = pixel_uvs.permute(0, 3, 1, 2, 4).reshape(N * K, H_out, W_out, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0401ec251a69a56b9db0ee6927d78fb3a2d9cec9aa9e5e9189c934bfe115a48c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('score_face')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
