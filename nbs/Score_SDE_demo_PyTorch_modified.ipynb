{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#@title Autoload all modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import importlib\n",
    "import os\n",
    "import functools\n",
    "import itertools\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "from losses import get_optimizer\n",
    "from models.ema import ExponentialMovingAverage\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_gan as tfgan\n",
    "import tqdm\n",
    "import io\n",
    "import likelihood\n",
    "import controllable_generation\n",
    "from utils import restore_checkpoint\n",
    "sns.set(font_scale=2)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "import models\n",
    "from models import utils as mutils\n",
    "from models import ncsnv2\n",
    "from models import ncsnpp\n",
    "from models import ddpm as ddpm_model\n",
    "from models import layerspp\n",
    "from models import layers\n",
    "from models import normalization\n",
    "import sampling\n",
    "from likelihood import get_likelihood_fn\n",
    "from sde_lib import VESDE\n",
    "from sampling import (ReverseDiffusionPredictor, \n",
    "                      LangevinCorrector, \n",
    "                      EulerMaruyamaPredictor, \n",
    "                      AncestralSamplingPredictor, \n",
    "                      NoneCorrector, \n",
    "                      NonePredictor,\n",
    "                      AnnealedLangevinDynamics)\n",
    "import datasets"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-05-25 22:40:57.423443: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# @title Load the score-based model\n",
    "\n",
    "from configs.ve import ffhq_256_ncsnpp_continuous as configs\n",
    "ckpt_filename = \"../exp/ve/ffhq_256_ncsnpp_continuous/checkpoint_48.pth\"\n",
    "config = configs.get_config()\n",
    "sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
    "sampling_eps = 1e-5\n",
    "\n",
    "batch_size = 1 #@param {\"type\":\"integer\"}\n",
    "config.training.batch_size = batch_size\n",
    "config.eval.batch_size = batch_size\n",
    "\n",
    "random_seed = 0 #@param {\"type\": \"integer\"}\n",
    "\n",
    "sigmas = mutils.get_sigmas(config)\n",
    "scaler = datasets.get_data_scaler(config)\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "score_model = mutils.create_model(config)\n",
    "\n",
    "optimizer = get_optimizer(config, score_model.parameters())\n",
    "ema = ExponentialMovingAverage(score_model.parameters(),\n",
    "                               decay=config.model.ema_rate)\n",
    "state = dict(step=0, optimizer=optimizer,\n",
    "             model=score_model, ema=ema)\n",
    "\n",
    "state = restore_checkpoint(ckpt_filename, state, config.device)\n",
    "ema.copy_to(score_model.parameters())\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m scaler \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mget_data_scaler(config)\n\u001b[1;32m     17\u001b[0m inverse_scaler \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mget_data_inverse_scaler(config)\n\u001b[0;32m---> 18\u001b[0m score_model \u001b[38;5;241m=\u001b[39m \u001b[43mmutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m get_optimizer(config, score_model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     21\u001b[0m ema \u001b[38;5;241m=\u001b[39m ExponentialMovingAverage(score_model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     22\u001b[0m                                decay\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mema_rate)\n",
      "File \u001b[0;32m~/score-face/nbs/../models/utils.py:92\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     90\u001b[0m model_name \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m     91\u001b[0m score_model \u001b[38;5;241m=\u001b[39m get_model(model_name)(config)\n\u001b[0;32m---> 92\u001b[0m score_model \u001b[38;5;241m=\u001b[39m \u001b[43mscore_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m score_model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mDataParallel(score_model)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_model\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "metadata": {
    "cellView": "form",
    "id": "-reedYgCU79v"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title Visualization code\n",
    "\n",
    "def image_grid(x):\n",
    "    size = config.data.image_size\n",
    "    channels = config.data.num_channels\n",
    "    img = x.reshape(-1, size, size, channels)\n",
    "    w = int(np.sqrt(img.shape[0]))\n",
    "    img = img.reshape((w, w, size, size, channels)).transpose((0, 2, 1, 3, 4)).reshape((w * size, w * size, channels))\n",
    "    return img\n",
    "\n",
    "\n",
    "def show_samples(x):\n",
    "    x = x.permute(0, 2, 3, 1).detach().cpu().numpy()\n",
    "    img = image_grid(x)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "id": "G8ei2Xsfg6JQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictor Corrector sampling\n",
    "\n",
    "\n",
    "Recommended settings:\n",
    "\n",
    " | dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |\n",
    "\n",
    "Check `probability_flow` to run PC sampling based on discretizing the probability flow ODE."
   ],
   "metadata": {
    "id": "8hbBGjCMNUsp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title PC sampling\n",
    "img_size = config.data.image_size\n",
    "channels = config.data.num_channels\n",
    "shape = (batch_size, channels, img_size, img_size)\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.15 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "sampling_fn = sampling.get_pc_sampler(sde, shape, predictor, corrector,\n",
    "                                      inverse_scaler, snr, n_steps=n_steps,\n",
    "                                      probability_flow=probability_flow,\n",
    "                                      continuous=config.training.continuous,\n",
    "                                      eps=sampling_eps, device=config.device)\n",
    "\n",
    "x, n = sampling_fn(score_model)\n",
    "show_samples(x)"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "_X41BhiLqJvM",
    "outputId": "8a5b3b5f-93ad-4baf-d66f-0a648f935170"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Probability flow ODE\n",
    "\n",
    "With black-box ODE solvers, we can produce samples, compute likelihoods, and obtain a uniquely identifiable encoding of any data point."
   ],
   "metadata": {
    "id": "0AdiQdwN2aFA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    " #@title ODE sampling\n",
    "\n",
    "shape = (batch_size, 3, 32, 32)\n",
    "sampling_fn = sampling.get_ode_sampler(sde,                                        \n",
    "                                       shape, \n",
    "                                       inverse_scaler,                                       \n",
    "                                       denoise=True, \n",
    "                                       eps=sampling_eps,\n",
    "                                       device=config.device)\n",
    "x, nfe = sampling_fn(score_model)\n",
    "show_samples(x)"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "iLQDfFvHSIGn",
    "outputId": "f1888e8b-4e70-446d-d248-9f1c1b6a7916"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title Likelihood computation\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=True, evaluation=True)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "likelihood_fn = likelihood.get_likelihood_fn(sde,                                              \n",
    "                                             inverse_scaler,                                             \n",
    "                                             eps=1e-5)\n",
    "for batch in eval_iter:\n",
    "  img = batch['image']._numpy()\n",
    "  img = torch.tensor(img).permute(0, 3, 1, 2).to(config.device)\n",
    "  img = scaler(img)\n",
    "  bpd, z, nfe = likelihood_fn(score_model, img)\n",
    "  bpds.extend(bpd)\n",
    "  print(f\"average bpd: {torch.tensor(bpds).mean().item()}, NFE: {nfe}\")"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "id": "MsdcLnhu7s46"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title Representations\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config, uniform_dequantization=False, evaluation=True)\n",
    "eval_batch = next(iter(eval_ds))\n",
    "eval_images = eval_batch['image']._numpy()\n",
    "shape = (batch_size, 3, 32, 32)\n",
    "\n",
    "likelihood_fn = likelihood.get_likelihood_fn(sde, inverse_scaler, eps=1e-5)\n",
    "sampling_fn = sampling.get_ode_sampler(sde, shape, inverse_scaler,\n",
    "                                       denoise=True, eps=sampling_eps, device=config.device)\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_grid(eval_images))\n",
    "plt.title('Original images')\n",
    "\n",
    "eval_images = torch.from_numpy(eval_images).permute(0, 3, 1, 2).to(config.device)\n",
    "_, latent_z, _ = likelihood_fn(score_model, scaler(eval_images))\n",
    "\n",
    "x, nfe = sampling_fn(score_model, latent_z)\n",
    "\n",
    "x = x.permute(0, 2, 3, 1).cpu().numpy()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis('off')\n",
    "plt.imshow(image_grid(x))\n",
    "plt.title('Reconstructed images')"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "id": "oe3rLGRm28nc",
    "outputId": "4d3b614b-df5b-4523-aa91-a223d6134397"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Controllable generation\n",
    "\n",
    "Several demonstrations on how to solve inverse problems with our SDE framework.\n",
    "\n",
    "Recommended settings\n",
    "\n",
    "| dataset | SDE | predictor | corrector | snr | n_steps |\n",
    "|:----:|:----:|:----------:|:--------:|:---:|:----:|\n",
    "|CIFAR-10 | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.16| 1|\n",
    "|CIFAR-10 | VP | EulerMaruyamaPredictor | None | - | - |\n",
    "|CIFAR-10 | subVP| EulerMaruyamaPredictor | None | - | - |\n",
    "| LSUN/CelebA-HQ/FFHQ 256px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.075 | 1 |\n",
    "| FFHQ 1024px | VE | ReverseDiffusionPredictor | LangevinCorrector | 0.15| 1 |"
   ],
   "metadata": {
    "id": "kaGYVD7KcoW6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#@title PC inpainting\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.15 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "\n",
    "pc_inpainter = controllable_generation.get_pc_inpainter(sde,\n",
    "                                                        predictor, corrector,\n",
    "                                                        inverse_scaler,\n",
    "                                                        snr=snr,\n",
    "                                                        n_steps=n_steps,\n",
    "                                                        probability_flow=probability_flow,\n",
    "                                                        continuous=config.training.continuous,\n",
    "                                                        denoise=True)\n",
    "batch = next(eval_iter)\n",
    "img = batch['image']._numpy()\n",
    "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
    "show_samples(img)\n",
    "\n",
    "mask = torch.ones_like(img)\n",
    "mask[:, :, :, 16:] = 0.\n",
    "show_samples(img * mask)\n",
    "\n",
    "x = pc_inpainter(score_model, scaler(img), mask)\n",
    "show_samples(x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-05-21 19:08:34.999624: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-21 19:08:35.143040: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2022-05-21 19:08:35.150054: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-21 19:08:35.153814: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-21 19:08:35.153875: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-21 19:08:35.153934: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-21 19:08:35.153971: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-21 19:08:35.167369: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-21 19:08:35.167450: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-21 19:08:35.285097: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-21 19:08:35.328427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-21 19:08:35.649557: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-21 19:08:35.732264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:0e:00.0 name: NVIDIA GeForce GTX 1080 computeCapability: 6.1\n",
      "coreClock: 1.7335GHz coreCount: 20 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 298.32GiB/s\n",
      "2022-05-21 19:08:35.733633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InternalError",
     "evalue": "CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#@title PC inpainting\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_ds, eval_ds, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m eval_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(eval_ds)\n\u001b[1;32m      4\u001b[0m bpds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/score-face/nbs/../datasets.py:141\u001b[0m, in \u001b[0;36mget_dataset\u001b[0;34m(config, uniform_dequantization, evaluation)\u001b[0m\n\u001b[1;32m    138\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFFHQ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCelebAHQ\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 141\u001b[0m   dataset_builder \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFRecordDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfrecords_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m   train_split_name \u001b[38;5;241m=\u001b[39m eval_split_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py:408\u001b[0m, in \u001b[0;36mTFRecordDatasetV2.__init__\u001b[0;34m(self, filenames, compression_type, buffer_size, num_parallel_reads)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    380\u001b[0m              filenames,\n\u001b[1;32m    381\u001b[0m              compression_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    382\u001b[0m              buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m              num_parallel_reads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `TFRecordDataset` to read one or more TFRecord files.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m  Each element of the dataset will contain a single TFRecord.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    ValueError: If any argument does not have the expected shape.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m   filenames \u001b[38;5;241m=\u001b[39m \u001b[43m_create_or_validate_filenames_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filenames \u001b[38;5;241m=\u001b[39m filenames\n\u001b[1;32m    411\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression_type \u001b[38;5;241m=\u001b[39m compression_type\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/data/ops/readers.py:64\u001b[0m, in \u001b[0;36m_create_or_validate_filenames_dataset\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m   filenames \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(_normalise_fspath, filenames)\n\u001b[0;32m---> 64\u001b[0m   filenames \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m filenames\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mstring:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`filenames` must be a `tf.Tensor` of dtype `tf.string` dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(filenames\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1553\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m preferred_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1552\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1555\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1556\u001b[0m     \u001b[38;5;66;03m# Could not coerce the conversion to use the preferred dtype.\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:339\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    338\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 339\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:264\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    275\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    279\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    300\u001b[0m   \u001b[38;5;124;03m\"\"\"Implementation of eager constant.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:97\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m---> 97\u001b[0m \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[0;32m/cluster/scratch/aarslan/miniconda3/envs/score_face/lib/python3.9/site-packages/tensorflow/python/eager/context.py:525\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    523\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_tfrt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    524\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetTfrt(opts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_tfrt)\n\u001b[0;32m--> 525\u001b[0m   context_handle \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_NewContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    527\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[0;31mInternalError\u001b[0m: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tbly_8RIjqJD",
    "outputId": "28ca290e-1079-4031-e37a-c69374398f76"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title PC colorizer\n",
    "train_ds, eval_ds, _ = datasets.get_dataset(config)\n",
    "eval_iter = iter(eval_ds)\n",
    "bpds = []\n",
    "\n",
    "predictor = ReverseDiffusionPredictor #@param [\"EulerMaruyamaPredictor\", \"AncestralSamplingPredictor\", \"ReverseDiffusionPredictor\", \"None\"] {\"type\": \"raw\"}\n",
    "corrector = LangevinCorrector #@param [\"LangevinCorrector\", \"AnnealedLangevinDynamics\", \"None\"] {\"type\": \"raw\"}\n",
    "snr = 0.16 #@param {\"type\": \"number\"}\n",
    "n_steps = 1 #@param {\"type\": \"integer\"}\n",
    "probability_flow = False #@param {\"type\": \"boolean\"}\n",
    "\n",
    "batch = next(eval_iter)\n",
    "img = batch['image']._numpy()\n",
    "img = torch.from_numpy(img).permute(0, 3, 1, 2).to(config.device)\n",
    "show_samples(img)\n",
    "gray_scale_img = torch.mean(img, dim=1, keepdims=True).repeat(1, 3, 1, 1)\n",
    "show_samples(gray_scale_img)\n",
    "gray_scale_img = scaler(gray_scale_img)\n",
    "pc_colorizer = controllable_generation.get_pc_colorizer(\n",
    "    sde, predictor, corrector, inverse_scaler,\n",
    "    snr=snr, n_steps=n_steps, probability_flow=probability_flow,\n",
    "    continuous=config.training.continuous, denoise=True\n",
    ")\n",
    "x = pc_colorizer(score_model, gray_scale_img)\n",
    "\n",
    "show_samples(x)"
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DsP-ayb8cupk",
    "outputId": "51272ecd-4ba3-4931-8a6d-358c6218e25b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Class-conditional generation\n",
    "\n"
   ],
   "metadata": {
    "id": "HiYRNB-Wk329"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check out the [class-conditional generation section](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55#scrollTo=HiYRNB-Wk329&line=3&uniqifier=1) in our [JAX demo](https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55?usp=sharing)"
   ],
   "metadata": {
    "id": "HTu-5e6S68Gb"
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Score SDE demo PyTorch",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "5039bcb0086f1a8e3ceb7068972048611f48699149712ad1b3124db6e7ca405f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.9 64-bit ('score_face': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}